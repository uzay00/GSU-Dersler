{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads\n",
    "\n",
    "1st Source: https://realpython.com/intro-to-python-threading/\n",
    "\n",
    "2nd Source: https://www.meccanismocomplesso.org/en/thread-in-python-threading-part-1/\n",
    "\n",
    "POSTED ON 30 NOVEMBER 2019 BY WEBMASTER\n",
    "Scarica l'articolo in formato PDF\n",
    "\n",
    "3rd Source: https://erdincuzun.com/ileri-python/multithreading-programlama/\n",
    "\n",
    "4th Source: https://www.analyticsvidhya.com/blog/2021/04/beginners-guide-to-threading-in-python/\n",
    "\n",
    "More about threads: http://nil.csail.mit.edu/6.824/2020/notes/l-rpc.txt\n",
    "\n",
    "> use multiple processes for CPU-intensive tasks; threads for (and during) I/O):\n",
    "\n",
    "\n",
    "## Thread (İş Parçacığı)\n",
    "\n",
    " - While in computer science, the term thread (thread of execution) stands for the smallest executable unit that can be scheduled in an operating system. \n",
    "\n",
    "\n",
    "> Bir işletim sistemi üzerinde herhangi bir dil ile kodlanmış ve bir compiler (derleyici) ile derlenmiş ve daha sonra hafızaya yüklenerek işlemcide çalıştırılan programlara process denir. Kısacası bir programın çalışan hali processtir.\n",
    "\n",
    "Threadler ise processlerin içerisinde yer alan eş zamanlı olarak çalışabilen iş parçacıklarıdır. Yani threadler sayesinde kodlarımızı ardaşıl olarak yürütmek yerine eş zamanlı olarak yürütebiliriz.\n",
    "\n",
    "![](https://erdincuzun.com/wp-content/uploads/2018/py_thread.jpg)\n",
    "\n",
    "\n",
    "Multithreading is a model of program execution that allows for multiple threads to be created within a process, executing independently but concurrently sharing process resources. \n",
    "\n",
    "> Depending on the hardware, threads can run fully parallel if they are distributed to their own CPU core.\n",
    "\n",
    "### Why do we need threading?\n",
    "\n",
    "__Concurent Programming__\n",
    "While one thread is idle/hanging, we can move on and process the other thread until the previous thread becomes active. TLDR- When one thread is waiting, you can process the other thread meanwhile.\n",
    "\n",
    "I/O concurrency\n",
    " - Client sends requests to many servers in parallel and waits for replies.\n",
    " - Server processes multiple client requests; each request may block.\n",
    "  - While waiting for the disk to read data for client X,\n",
    "      process a request from client Y.\n",
    "\n",
    "__Practical Example__\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*g8rKYd8cyTzIwiAzJ0ka_Q.png)\n",
    "\n",
    "> Imagine what would be the situation without threading. You would have to wait for the video to get downloaded once in a while, watch the segment that was fetched, wait for the next segment to get downloaded, and so on.\n",
    "\n",
    "![](https://files.realpython.com/media/IOBound.4810a888b457.png)\n",
    " \n",
    "> Thanks to threading, we can divide the two processes into different threads. While one thread fetches data (that is, it is in hang/sleep mode), the other thread can show you the amazing performance of Morgan Freeman.\n",
    "\n",
    "![](https://files.realpython.com/media/Threading.3eef48da829e.png)\n",
    "\n",
    "#### Application responsiveness is improved \n",
    "\n",
    "__Threading rocks for IO Bound__\n",
    "It uses multiple threads to have multiple open requests out to web sites at the same time, allowing your program to overlap the waiting times and get the final result faster! Yippee! That was the goal.\n",
    "\n",
    "\n",
    "\n",
    ">It is also much useful for you as a Data Scientist. For example, when you scrape the data from multiple web pages, you can simply deploy them in multiple threads and make it faster. Even when you push the data to a server, you can do so in multiple threads, so that when one thread is idle others can be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This is a warning message\n",
      "ERROR:root:This is an error message\n",
      "CRITICAL:root:This is a critical message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.debug('This is a debug message')\n",
    "logging.info('This is an info message')\n",
    "logging.warning('This is a warning message')\n",
    "logging.error('This is an error message')\n",
    "logging.critical('This is a critical message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n",
      "DEBUG:root:This will get logged\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "logging.debug('This will get logged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Main    : before creating thread\n",
      "INFO:root:Main    : before running thread\n",
      "INFO:root:Thread 1: starting\n",
      "INFO:root:Main    : wait for the thread to finish\n",
      "INFO:root:Thread 1: finishing\n",
      "INFO:root:Main    : all done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def thread_function(name):\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "    time.sleep(3)\n",
    "    logging.info(\"Thread %s: finishing\", name)\n",
    "\n",
    "\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,\n",
    "                    datefmt=\"%H:%M:%S\")\n",
    "\n",
    "logging.info(\"Main    : before creating thread\")\n",
    "x = threading.Thread(target=thread_function, args=(1,))\n",
    "\n",
    "logging.info(\"Main    : before running thread\")\n",
    "x.start()\n",
    "\n",
    "logging.info(\"Main    : wait for the thread to finish\")\n",
    "# To tell one thread to wait for another thread to finish, you call .join(). \n",
    "x.join()\n",
    "\n",
    "logging.info(\"Main    : all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the threading module we import Thread,  args is used to pass parameters within the thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Threads\n",
    "\n",
    "with `join()` we can have more control over each individual thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Main    : create and start thread 0.\n",
      "INFO:root:Thread 0: starting\n",
      "INFO:root:Main    : create and start thread 1.\n",
      "INFO:root:Thread 1: starting\n",
      "INFO:root:Main    : create and start thread 2.\n",
      "INFO:root:Thread 2: starting\n",
      "INFO:root:Main    : create and start thread 3.\n",
      "INFO:root:Thread 3: starting\n",
      "INFO:root:Main    : create and start thread 4.\n",
      "INFO:root:Thread 4: starting\n",
      "INFO:root:Main    : before joining thread 0.\n",
      "INFO:root:Thread 0: finishing\n",
      "INFO:root:Main    : thread 0 done\n",
      "INFO:root:Thread 2: finishing\n",
      "INFO:root:Thread 1: finishing\n",
      "INFO:root:Main    : before joining thread 1.\n",
      "INFO:root:Thread 3: finishing\n",
      "INFO:root:Main    : thread 1 done\n",
      "INFO:root:Main    : before joining thread 2.\n",
      "INFO:root:Main    : thread 2 done\n",
      "INFO:root:Thread 4: finishing\n",
      "INFO:root:Main    : before joining thread 3.\n",
      "INFO:root:Main    : thread 3 done\n",
      "INFO:root:Main    : before joining thread 4.\n",
      "INFO:root:Main    : thread 4 done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def thread_function(name):\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "    time.sleep(2)\n",
    "    logging.info(\"Thread %s: finishing\", name)\n",
    "\n",
    "\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,\n",
    "                    datefmt=\"%H:%M:%S\")\n",
    "\n",
    "threads = list()\n",
    "for index in range(5):\n",
    "    logging.info(\"Main    : create and start thread %d.\", index)\n",
    "    x = threading.Thread(target=thread_function, args=(index,))\n",
    "    threads.append(x)\n",
    "    x.start()\n",
    "\n",
    "for index, thread in enumerate(threads):\n",
    "    logging.info(\"Main    : before joining thread %d.\", index)\n",
    "    thread.join()\n",
    "    logging.info(\"Main    : thread %d done\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Thread 0: starting\n",
      "INFO:root:Thread 1: starting\n",
      "INFO:root:Thread 2: starting\n",
      "INFO:root:Thread 0: finishing\n",
      "INFO:root:Thread 2: finishing\n",
      "INFO:root:Thread 1: finishing\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# [rest of code]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        executor.map(thread_function, range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main start\n",
      "Thread 1 started\n",
      "Thread 2 started\n",
      "Thread 2 ended\n",
      "Thread 1 ended\n",
      "Main end\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def thread1():\n",
    "    print(\"Thread 1 started\")\n",
    "    time.sleep(10)\n",
    "    print(\"Thread 1 ended\")\n",
    "\n",
    "def thread2():\n",
    "    print(\"Thread 2 started\")\n",
    "    time.sleep(4)\n",
    "    print(\"Thread 2 ended\")\n",
    "\n",
    "print(\"Main start\")\n",
    "t1 = Thread(target=thread1)\n",
    "t2 = Thread(target=thread2)\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "time.sleep(12)\n",
    "print(\"Main end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted a different sequence? \n",
    "> For example we want the program to wait for the end of the first thread before it stops.\n",
    "\n",
    "The thread.join() function exists in the threading module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main start\n",
      "Thread 1 started\n",
      "Thread 1 ended\n",
      "Thread 2 started\n",
      "Thread 2 ended\n",
      "Main end\n"
     ]
    }
   ],
   "source": [
    "print(\"Main start\")\n",
    "t1 = Thread(target=thread1)\n",
    "t2 = Thread(target=thread2)\n",
    "t1.start()\n",
    "t1.join()\n",
    "\n",
    "t2.start()\n",
    "t2.join()\n",
    "print(\"Main end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ThreadPoolExecutor\n",
    "When threads begin to be many, an efficient way to manage them is the ThreadPoolExecutor. This interface belongs to the concurrent.futures module and is created as a context manager, using the with statement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main start\n",
      "Thread 1 started\n",
      "Thread 2 started\n",
      "Thread 2 ended\n",
      "Thread 1 ended\n",
      "Main end\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def thread1():\n",
    "    print(\"Thread 1 started\")\n",
    "    time.sleep(10)\n",
    "    print(\"Thread 1 ended\")\n",
    "\n",
    "def thread2():\n",
    "    print(\"Thread 2 started\")\n",
    "    time.sleep(4)\n",
    "    print(\"Thread 2 ended\")\n",
    "\n",
    "print(\"Main start\")\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    executor.submit(thread1)\n",
    "    executor.submit(thread2)\n",
    "\n",
    "print(\"Main end\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race Conditions\n",
    "\n",
    "> Thread is a useful structuring tool, but can be tricky\n",
    "\n",
    "Race conditions can occur when two or more threads access a shared piece of data or resource.\n",
    "\n",
    "\n",
    "These particular conditions occur when two or more threads access a set of shared data or resources. If not well managed, a thread’s access and modification to these resources can lead to inconsistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDatabase:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "\n",
    "    def update(self, name):\n",
    "        logging.info(\"Thread %s: starting update\", name)\n",
    "        local_copy = self.value\n",
    "        local_copy += 1\n",
    "        time.sleep(0.1)\n",
    "        self.value = local_copy\n",
    "        logging.info(\"Thread %s: finishing update\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Testing update. Starting value is 0.\n",
      "INFO:root:Thread 0: starting update\n",
      "INFO:root:Thread 1: starting update\n",
      "INFO:root:Thread 0: finishing update\n",
      "INFO:root:Thread 1: finishing update\n",
      "INFO:root:Testing update. Ending value is 1.\n"
     ]
    }
   ],
   "source": [
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,\n",
    "                    datefmt=\"%H:%M:%S\")\n",
    "\n",
    "database = FakeDatabase()\n",
    "logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for index in range(2):\n",
    "        executor.submit(database.update, index)\n",
    "logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://files.realpython.com/media/intro-threading-shared-database.267a5d8c6aa1.png)\n",
    "\n",
    "There are two things to keep in mind when thinking about race conditions:\n",
    "\n",
    " - Even an operation like x += 1 takes the processor many steps. Each of these steps is a separate instruction to the processor.\n",
    "\n",
    " - The operating system can swap which thread is running at any time. A thread can be swapped out after any of these small instructions. This means that a thread can be put to sleep to let another thread run in the middle of a Python statement.\n",
    " \n",
    "The dis module supports the analysis of CPython bytecode by disassembling it. \n",
    " https://docs.python.org/3/library/dis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_CONST               1 (1)\n",
      "              4 INPLACE_ADD\n",
      "              6 STORE_FAST               0 (x)\n",
      "              8 LOAD_CONST               0 (None)\n",
      "             10 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "def inc(x):\n",
    "    x += 1\n",
    "\n",
    "import dis\n",
    "dis.dis(inc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It’s rare to get a race condition like this to occur, but remember that an infrequent event taken over millions of iterations becomes likely to happen. The rarity of these race conditions makes them much, much harder to debug than regular bugs.\n",
    "\n",
    "# Basic Synchronization Using Lock\n",
    "\n",
    "Lock in Python. \n",
    " - In some other languages this same idea is called a mutex. \n",
    " - Mutex comes from MUTual EXclusion, which is exactly what a Lock does.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDatabase:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def locked_update(self, name):\n",
    "        logging.info(\"Thread %s: starting update\", name)\n",
    "        logging.debug(\"Thread %s about to lock\", name)\n",
    "        with self._lock:\n",
    "            logging.debug(\"Thread %s has lock\", name)\n",
    "            local_copy = self.value\n",
    "            local_copy += 1\n",
    "            time.sleep(0.1)\n",
    "            self.value = local_copy\n",
    "            logging.debug(\"Thread %s about to release lock\", name)\n",
    "        logging.debug(\"Thread %s after release\", name)\n",
    "        logging.info(\"Thread %s: finishing update\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Testing update. Starting value is 0.\n",
      "INFO:root:Thread 0: starting update\n",
      "INFO:root:Thread 1: starting update\n",
      "DEBUG:root:Thread 0 about to lock\n",
      "DEBUG:root:Thread 1 about to lock\n",
      "DEBUG:root:Thread 0 has lock\n",
      "DEBUG:root:Thread 0 about to release lock\n",
      "DEBUG:root:Thread 0 after release\n",
      "DEBUG:root:Thread 1 has lock\n",
      "INFO:root:Thread 0: finishing update\n",
      "DEBUG:root:Thread 1 about to release lock\n",
      "DEBUG:root:Thread 1 after release\n",
      "INFO:root:Thread 1: finishing update\n",
      "INFO:root:Testing update. Ending value is 2.\n"
     ]
    }
   ],
   "source": [
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,\n",
    "                    datefmt=\"%H:%M:%S\")\n",
    "\n",
    "database = FakeDatabase()\n",
    "logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for index in range(2):\n",
    "        executor.submit(database.locked_update, index)\n",
    "logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Testing update. Starting value is 0.\n",
      "INFO:root:Thread 0: starting update\n",
      "INFO:root:Thread 1: starting update\n",
      "DEBUG:root:Thread 0 about to lock\n",
      "DEBUG:root:Thread 1 about to lock\n",
      "DEBUG:root:Thread 0 has lock\n",
      "DEBUG:root:Thread 0 about to release lock\n",
      "DEBUG:root:Thread 0 after release\n",
      "DEBUG:root:Thread 1 has lock\n",
      "INFO:root:Thread 0: finishing update\n",
      "DEBUG:root:Thread 1 about to release lock\n",
      "DEBUG:root:Thread 1 after release\n",
      "INFO:root:Thread 1: finishing update\n",
      "INFO:root:Testing update. Ending value is 2.\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "database = FakeDatabase()\n",
    "logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for index in range(2):\n",
    "        executor.submit(database.locked_update, index)\n",
    "logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fridge Example\n",
    "\n",
    "A thread will call `my_lock.acquire()` to get the lock. If the lock is already held, the calling thread will wait until it is released. There’s an important point here. If one thread gets the lock but never gives it back, your program will be stuck.\n",
    "\n",
    ">Thread senkronizasyonu kilit mekanizması sağlanır. Lock() metodu çağırılarak bir kilit oluşturulur. Bu metod threadlerin eş zamanlı olarak çalışmasını engelleyen bir mekanizmadır. Yani bir thread sonlanır ve diğer thread çalışmasına ondan sonra devam eder. Kilit acquire() fonksiyonu ile aktif hale gelir, release() fonksiyonu ile serbest bırakılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread increment:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uzaycetin/opt/anaconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread decrement:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uzaycetin/opt/anaconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/uzaycetin/opt/anaconda3/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-7aae86d774ad>\", line 12, in decrement\n",
      "NameError: name 'count' is not defined\n",
      "    self.run()\n",
      "  File \"/Users/uzaycetin/opt/anaconda3/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-7aae86d774ad>\", line 4, in increment\n",
      "NameError: name 'count' is not defined\n"
     ]
    }
   ],
   "source": [
    "def increment():\n",
    "    global count\n",
    "    for i in range(3):\n",
    "        count += 1\n",
    "        print('incrementer: ', count )\n",
    "        time.sleep(0.1)\n",
    "\n",
    "\n",
    "def decrement():\n",
    "    global count\n",
    "    for i in range(5):\n",
    "        count -= 1\n",
    "        print('decrementer: ', count )\n",
    "        time.sleep(0.1)\n",
    "\n",
    "inc = threading.Thread(name='increment', target=increment)\n",
    "dec = threading.Thread(name='decrement', target=decrement)\n",
    "\n",
    "inc.start()\n",
    "dec.start()\n",
    "\n",
    "inc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-26780ddf2751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kilit olmadan')\n",
    "print('\\t>>3 defa arttir, 5 defa azalt \\n\\t>>sonuc', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threading example\n",
    "import threading\n",
    "import time\n",
    "\n",
    "lock = threading.Lock()\n",
    "count = 0\n",
    "\n",
    "def increment():\n",
    "    global count\n",
    "    for i in range(3):\n",
    "        lock.acquire()\n",
    "        try:\n",
    "            count += 1\n",
    "            print('incrementer: ', count )\n",
    "        finally:\n",
    "            lock.release()\n",
    "            time.sleep(0.1)\n",
    "\n",
    "\n",
    "def decrement():\n",
    "    global count\n",
    "    for i in range(5):\n",
    "        lock.acquire()\n",
    "        try:\n",
    "            count -= 1\n",
    "            print('decrementer: ', count )\n",
    "        finally:\n",
    "            lock.release()\n",
    "            time.sleep(0.1)\n",
    "\n",
    "inc = threading.Thread(name='increment', target=increment)\n",
    "dec = threading.Thread(name='decrement', target=decrement)\n",
    "\n",
    "inc.start()\n",
    "dec.start()\n",
    "\n",
    "inc.join()\n",
    "dec.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kilit oldugunda')\n",
    "print('\\t>>3 defa arttir, 5 defa azalt \\n\\t>>sonuc', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dec.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "class buzdolabi:\n",
    "    def __init__(self):\n",
    "        self.ayran = 0\n",
    "\n",
    "    def ayran_al(self):\n",
    "        local_copy = self.ayran\n",
    "        local_copy += 1\n",
    "        time.sleep(0.1)\n",
    "        self.ayran = local_copy\n",
    "\n",
    "    def ayran_ic(self):\n",
    "        local_copy = self.ayran\n",
    "        local_copy -= 1\n",
    "        time.sleep(0.1)\n",
    "        self.ayran = local_copy\n",
    "        \n",
    "dolap = buzdolabi()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for index in range(9):\n",
    "        executor.submit(dolap.ayran_al)\n",
    "    for index in range(2):\n",
    "        executor.submit(dolap.ayran_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolap.ayran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kilit olmadan')\n",
    "print('\\t>>9 defa ayran al, 2 defa ayrani ic \\n\\t>>sonuc', dolap.ayran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "class buzdolabi:\n",
    "    def __init__(self):\n",
    "        self.ayran = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def ayran_al(self):\n",
    "        with self._lock:\n",
    "            local_copy = self.ayran\n",
    "            local_copy += 1\n",
    "            time.sleep(0.1)\n",
    "            self.ayran = local_copy\n",
    "\n",
    "    def ayran_ic(self):\n",
    "        with self._lock:\n",
    "            local_copy = self.ayran\n",
    "            local_copy -= 1\n",
    "            time.sleep(0.1)\n",
    "            self.ayran = local_copy\n",
    "        \n",
    "dolap = buzdolabi()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for index in range(9):\n",
    "        executor.submit(dolap.ayran_al)\n",
    "    for index in range(2):\n",
    "        executor.submit(dolap.ayran_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolap.ayran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kilit olmadan')\n",
    "print('\\t>>9 defa ayran al, 2 defa ayrani ic \\n\\t>>sonuc', dolap.ayran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producer-Consumer Threading\n",
    "\n",
    "This example only allows a single value in the pipeline at a time.\n",
    "\n",
    "Producer\n",
    "- imagine a program that needs to read messages from a network and write them to disk. \n",
    "- The program does not request a message when it wants. It must be listening and accept messages as they come in.\n",
    "\n",
    "- The messages will not come in at a regular pace, but will be coming in bursts.\n",
    "\n",
    "Consumer\n",
    "\n",
    " - once you have a message, you need to write it to a database. The database access is slow, but fast enough to keep up to the average pace of messages. It is not fast enough to keep up when a burst of messages comes in.\n",
    " \n",
    " \n",
    "`.acquire()`\n",
    " - block until the lock is unlocked\n",
    " \n",
    "`.release()`\n",
    " - When the lock is locked, reset it to unlocked, and return. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "SENTINEL = object()\n",
    "\n",
    "def producer(pipeline):\n",
    "    \"\"\"Pretend we're getting a message from the network.\"\"\"\n",
    "    for index in range(10):\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "    # Send a sentinel message to tell consumer we're done\n",
    "    # The producer also uses a SENTINEL value to signal the consumer to stop after it has sent ten values\n",
    "    pipeline.set_message(SENTINEL, \"Producer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a fake message, the producer gets a random number between one and one hundred. It calls .set_message() on the pipeline to send it to the consumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(pipeline):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    message = 0\n",
    "    # If it gets the SENTINEL value, it returns from the function, which will terminate the thread.\n",
    "    while message is not SENTINEL:\n",
    "        # The consumer calls .get_message(), which reads the message and calls .release() on the .producer_lock, \n",
    "        # thus allowing the producer to insert next message to the pipeline\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "        if message is not SENTINEL:\n",
    "            logging.info(\"Consumer storing message: %s\", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consumer reads a message from the pipeline and writes it to a fake database, which in this case is just printing it to the display. If it gets the SENTINEL value, it returns from the function, which will terminate the thread.\n",
    "\n",
    "The Pipeline in this version of your code has three members:\n",
    "\n",
    " - message stores the message to pass.\n",
    " - producer_lock is a threading.Lock object that restricts access to the message by the producer thread.\n",
    " - consumer_lock is also a threading.Lock that restricts access to the message by the consumer thread.\n",
    " \n",
    "> The producer is allowed to add a new message, but the consumer needs to wait until a message is present.\n",
    "\n",
    "This is the call that will make the consumer wait until a message is ready.\n",
    " - `.get_message()` calls `.acquire()` on the `consumer_lock`. \n",
    " \n",
    "Releasing this lock is what allows the producer to insert the next message into the pipeline.\n",
    " - Once the consumer has acquired the `.consumer_lock`, it copies out the value in .message and then calls `.release()` on the `.producer_lock`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    Class to allow a single element pipeline between producer and consumer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.message = 0\n",
    "        self.producer_lock = threading.Lock()\n",
    "        self.consumer_lock = threading.Lock()\n",
    "        \n",
    "        # the producer is allowed to add a new message to the pipeline\n",
    "        # the consumer will wait until a message is ready in the Pipeline. \n",
    "        self.consumer_lock.acquire()\n",
    "\n",
    "    def get_message(self, name):\n",
    "        logging.debug(\"%s:about to acquire getlock\", name)\n",
    "        # the consumer will wait until a message is ready in the Pipeline. \n",
    "        self.consumer_lock.acquire()\n",
    "        logging.debug(\"%s:have getlock\", name)\n",
    "        message = self.message\n",
    "        logging.debug(\"%s:about to release setlock\", name)\n",
    "        # The consumer will then release the lock, \n",
    "        #     allowing the producer to insert another message into the pipeline.\n",
    "        self.producer_lock.release()\n",
    "        logging.debug(\"%s:setlock released\", name)\n",
    "        return message\n",
    "\n",
    "    def set_message(self, message, name):\n",
    "        logging.debug(\"%s:about to acquire setlock\", name)\n",
    "        # the producer will wait until previous message is consumed by the consumer. \n",
    "        # self.producer_lock.release() in get_message is waited here!!\n",
    "        self.producer_lock.acquire()\n",
    "        logging.debug(\"%s:have setlock\", name)\n",
    "        self.message = message\n",
    "        logging.debug(\"%s:about to release getlock\", name)\n",
    "        self.consumer_lock.release()\n",
    "        logging.debug(\"%s:getlock released\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,\n",
    "                    datefmt=\"%H:%M:%S\")\n",
    "\n",
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "pipeline = Pipeline()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    executor.submit(producer, pipeline)\n",
    "    executor.submit(consumer, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "class Pipeline:\n",
    "    #\"\"\"\n",
    "    Class to allow a single element pipeline between producer and consumer.\n",
    "    #\"\"\"\n",
    "    def __init__(self):\n",
    "        self.message = 0\n",
    "        self.producer_lock = threading.Lock()\n",
    "        self.consumer_lock = threading.Lock()\n",
    "        self.consumer_lock.acquire()\n",
    "\n",
    "    def get_message(self, name):\n",
    "        self.consumer_lock.acquire()\n",
    "        message = self.message\n",
    "        self.producer_lock.release()\n",
    "        return message\n",
    "\n",
    "    def set_message(self, message, name):\n",
    "        self.producer_lock.acquire()\n",
    "        self.message = message\n",
    "        self.consumer_lock.release()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producer-Consumer Using Queue\n",
    "\n",
    "If you want to be able to handle more than one value in the pipeline at a time, you’ll need a data structure for the pipeline that allows the number to grow and shrink as data backs up from the producer.\n",
    "\n",
    "The threading.Event object allows one thread to signal an event while many other threads can be waiting for that event to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producer(pipeline, event):\n",
    "    \"\"\"Pretend we're getting a number from the network.\"\"\"\n",
    "    while not event.is_set():\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "    logging.info(\"Producer received EXIT event. Exiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(pipeline, event):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    while not event.is_set() or not pipeline.empty():\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "        logging.info(\n",
    "            \"Consumer storing message: %s  (queue size=%s)\",\n",
    "            message,\n",
    "            pipeline.qsize(),\n",
    "        )\n",
    "\n",
    "    logging.info(\"Consumer received EXIT event. Exiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "class Pipeline(queue.Queue):\n",
    "    def __init__(self):\n",
    "        super().__init__(maxsize=10)\n",
    "\n",
    "    def get_message(self, name):\n",
    "        logging.debug(\"%s:about to get from queue\", name)\n",
    "        value = self.get()\n",
    "        logging.debug(\"%s:got %d from queue\", name, value)\n",
    "        return value\n",
    "\n",
    "    def set_message(self, value, name):\n",
    "        logging.debug(\"%s:about to add %d to queue\", name, value)\n",
    "        self.put(value)\n",
    "        logging.debug(\"%s:added %d to queue\", name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,\n",
    "                    datefmt=\"%H:%M:%S\")\n",
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "pipeline = Pipeline()\n",
    "event = threading.Event()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    executor.submit(producer, pipeline, event)\n",
    "    executor.submit(consumer, pipeline, event)\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    logging.info(\"Main: about to set event\")\n",
    "    # All threads waiting for it to become true are awakened.\n",
    "    event.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try playing with different queue sizes and calls to time.sleep() in the producer or the consumer to simulate longer network or disk access times respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producer-Consumer Problem in Python\n",
    "\n",
    "https://www.askpython.com/python/producer-consumer-problem\n",
    "\n",
    "![](https://www.askpython.com/wp-content/uploads/2021/06/Producer-Consumer-Problem-in-Python-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of 3 components:\n",
    "- Bounded Buffer: A buffer is temporary storage\n",
    "- Producer Thread: A Producer Thread is one that generates some data, puts it into the buffer,\n",
    "- Consumer Thread: A Consumer Thread is one that consumes the data present inside the buffer\n",
    "\n",
    "Problems\n",
    " - __Fast Producer__: If the Producer Thread is trying to generate the data into the buffer and found that the buffer is already full, it must await\n",
    " \n",
    " - __Fast Consumer__ :If the Consumer Thread is trying to consume the data from the buffer but found that the buffer is empty,\n",
    " \n",
    " - __Race conditions on Buffer__ : \n",
    "  - Producer Thread should add the data to the buffer and the Consumer Thread should wait\n",
    "  -  Producer Thread should wait while the Consumer Thread is working on shared buffer to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
